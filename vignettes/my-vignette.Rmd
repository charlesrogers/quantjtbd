---
title: "Quant JTBD Package"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Quant JTBD Package}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
```
------------------------------------------------------------------------

## What the QuantJTBD Package Does
The QuantJTBD package takes Jobs to Be Done^[If you'd like a good primer on JTBD, check out [this article](https://medium.com/swlh/a-jobs-to-be-done-jtbd-primer-11585d23ceec)] survey data (in the Outcome Driven Innovation^[see Tony Ulwick's fabulous [What Customers Want](https://www.amazon.com/What-Customers-Want-Outcome-Driven-Breakthrough/dp/0071408673)] format) and measures the frequency.

This means you need to ask your questions on a 1-5 likert scale and recode the scales (Not important at all, Slightly important, Somewhat important, Very important, Extremely important) as numeric factors (1-5)

### Quant JTBD Methodology

The scores are calculated in the traditional Outcome Driven Innovation way:
```{r eval=FALSE}
importance + importance - satisfaction
example: 8.4 + 8.4 - 6.7 = 10.1
```
To get a bit more specific, since someone's satisfaction with a job doesn't change how important it is, importance should be the floor for opportunity, so we just use the importance score as the opportunity score:
```{r eval=FALSE}
importance + (if importance < satisfaction, 0, - satisfaction)
incorrect calculation: 6.7 + 6.7 - 8.4 = 5
correct calculation: 6.7 + (if 8.4 > 6.7, 0, else 6.7 - 8.4) = 6.7

```

#### Statistical Significance When Comparing Job Scores between Groups

At some point you will compare JTBD scores (imp, sat, or opp) of >=2 groups of users and someone will (_should_) ask which differences are statistically significant.
We use the Wilcoxon Rank-sum test^[If the means of the opp scores are normally distributed we use the ] as we don't know if the means are normally distributed.

* are we even comparing means [pinned]
* t-test: 
* maybe a chi square (which is for binary outcomes) [pinned] and we can do correlation
* ANOVA: 3 or more groups with categories with means
* ~Paired samples t-test~

```{r eval=FALSE}
<- wilcox.test()
```

### Measurement

* Calculates the importance, satisfaction, and opportunity scores
* Compares the importance, satisfaction, and opportunity scores between two, three, and four groups
* Calculates the statistical significance between paired group differences at the importance, satisfaction, and opportunity score level.

### Visulization

Generates JTBD graphics such as: 

#### Opportunity Score Matrix (Importance x Satisfaction)

##### Labeled Matrix > 10
```{r load-packages, someplot, echo=FALSE, warning=FALSE, message=FALSE}
library(dplyr)
library(magrittr)
library(knitr)
library(paletteer)
library(gt)
library(ggplot2)
objective <- c("Minimize_time_to_do_job_1","Minimize_time_to_do_job_2","Minimize_time_to_do_job_3","Minimize_time_to_do_job_4","Minimize_time_to_do_job_5","Minimize_time_to_do_job_6","Minimize_time_to_do_job_7","Minimize_time_to_do_job_8","Minimize_time_to_do_job_9","Minimize_time_to_do_job_10")
 df_test <- tibble(objective)

project_name_short <- "Your JTBD Project"
sample_description <- "N=500 Sample Description"
title_string <- "Your JTBD Project"
subtitle_string <- "Your JTBD Project"

df_test <- df_test %>%
  mutate(`Importance` = round(runif(10,6,9.75),1)) %>%
  mutate(`Satisfaction` = round(runif(10,5,9),1)) %>%
  mutate(opportunity_score = case_when(`Importance`>`Satisfaction`~`Importance`+`Importance`-`Satisfaction`,
                                                    `Satisfaction`>=`Importance`~`Importance`),
         rank_total_population=rank(opportunity_score))

df_test %>%
    mutate(high_opportunity=if_else(opportunity_score>=10,"high-priority opportunity","other opportunity")) %>%
    ggplot(aes(x=`Importance`,y=`Satisfaction`,color=high_opportunity,label=objective))+geom_point() + 
    geom_text(aes(label=ifelse(opportunity_score>=10,as.character(objective),'')),hjust=0,vjust=0,angle = 45) +
    #coord_flip() +
    #+ scale_x_discrete(drop=FALSE)
    labs(title=title_string,subtitle=subtitle_string,x="Importance",y="Satisfaction",color="Opportunity\nValue",fill="", size="")+#,caption=paste0("Data as of ",today()) ,caption="NYC Research Team" ,caption=paste0("Created ",today())
    theme(text=element_text(family = "Roboto"),
          panel.grid.major = element_line(color = "#DAE1E7"),
          panel.background = element_blank(),axis.text = element_text(size = 12),
          axis.text.x = element_text(margin = margin(t = 5)),#hjust = 1,angle=90
          axis.text.y = element_text(margin = margin(r = 5)),
          axis.title = element_text (size = 15),
          axis.line = element_line(),
          axis.title.y = element_text(margin = margin(r = 10), hjust = 0.5),
          axis.title.x = element_text(margin = margin(t = 10), hjust = 0.5),
          plot.caption = element_text(size = 8,
                                      margin = margin(t = 10),
                                      color = "#3D4852"), 
          title = element_text (size = 15,margin = margin(b = 10)),) +
    guides(fill=FALSE) +
    expand_limits(x=0,y=0) +
    # scale_x_discrete(drop=FALSE) + 
    #scale_x_continuous(expand=c(0,0)) + scale_y_continuous(expand=c(0,0)) #+
    coord_cartesian(xlim=c(1,10),ylim=c(1,10))

```

#### Job Score Tables
These tables display importance, satisfaction, and opportunity by job step (ranked within step)

```{r someplot, echo=FALSE, warning=FALSE, message=FALSE}
# {r load-packages, someplot, echo=FALSE, warning=FALSE, message=FALSE}
# library(dplyr)
# library(magrittr)
# library(knitr)
# library(paletteer)
# library(gt)
usethis::use_pipe()
objective <- c("Minimize_time_to_do_job_1","Minimize_time_to_do_job_2","Minimize_time_to_do_job_3","Minimize_time_to_do_job_4","Minimize_time_to_do_job_5","Minimize_time_to_do_job_6","Minimize_time_to_do_job_7","Minimize_time_to_do_job_8","Minimize_time_to_do_job_9","Minimize_time_to_do_job_10")
 df_test <- tibble(objective)

project_name_short <- "Your JTBD Project"
sample_description <- "N=500 Sample Description"

df_test <- df_test %>%
  mutate(`Importance` = round(runif(10,6,9.75),1)) %>%
  mutate(`Satisfaction` = round(runif(10,5,9),1)) %>%
  mutate(`Opportunity Score` = case_when(`Importance`>`Satisfaction`~`Importance`+`Importance`-`Satisfaction`,
                                                    `Satisfaction`>=`Importance`~`Importance`),
         rank_total_population=rank(`Opportunity Score`))


  df_test %>%
    select(-rank_total_population) %>%
    gt(groupname_col = "Job_Step",
       rowname_col = "Objective") %>%
    tab_header(
      title = md(paste0('Top Opportunities: ',project_name_short)),
      subtitle = html(paste0("Sample: ",sample_description))
    ) %>%
    tab_options(
      column_labels.border.bottom.color = "black",
      column_labels.border.bottom.width= px(3),
      heading.align = "left"
    ) %>%
    tab_style(
      style = cell_text(color = "green",weight = "normal"),
      locations = list(
        cells_body(
          columns = vars(`Opportunity Score`),
          rows = `Opportunity Score` >= 10
        ))) %>%
    tab_style(
      style = cell_text(color = "darkgreen",weight = "bold"),
      locations = list(
        cells_body(
          columns = vars(`Opportunity Score`),
          rows = `Opportunity Score` >= 12
        ))) %>%
    tab_style(
      style = cell_text(color = "black", weight = "bold"),
      locations = list(
        cells_row_groups(),
        cells_column_labels(everything())))

```

#### Cleveland (lollipop) graphs
Compae the differences of scores between 2 groups 

```{r eval=FALSE}
get_cleveland_graph(opportunity_number_of_ffs,opportunity_number_of_ffs$objective,opportunity_number_of_ffs$opportunity_score_Sub_10,opportunity_number_of_ffs$opportunity_score_Over_10,"uu Opportunities By Number of ffs","<=10 = Blue, >10 = Red")
#
get_cleveland_graph()
get_cleveland_graph <- function(data, objective, group_1,group_2,title_string,subtitle_string) {
  objective <- enquo(objective)
  group_1 <- enquo(group_1)
  group_2 <- enquo(group_2)
  # print(dplyr::quo_name(!!group_1))
  plot <- data %>%
    ggplot() + geom_segment(aes(x=!!objective, xend=!!objective, y=!!group_1, yend=!!group_2), color="grey") +
    geom_point(aes(x=!!objective, y=!!group_1), color="blue", size=3) +
    geom_point(aes(x=!!objective, y=!!group_2), color="red", size=3) +
    coord_flip()+
    labs(title=title_string,subtitle=subtitle_string,x="Objectives",y="Scores",color="",fill="", size="")+#,caption=paste0("Data as of ",today()) ,caption="NYC Research Team" ,caption=paste0("Created ",today())
    theme(text=element_text(family = "Roboto"),
          panel.grid.major = element_line(color = "#DAE1E7"),
          panel.background = element_blank(),axis.text = element_text(size = 12),
          axis.text.x = element_text(margin = margin(t = 5)),#hjust = 1,angle=90
          axis.text.y = element_text(margin = margin(r = 5)),
          axis.title = element_text (size = 15),
          axis.line = element_line(),
          axis.title.y = element_text(margin = margin(r = 10), hjust = 0.5),
          axis.title.x = element_text(margin = margin(t = 10), hjust = 0.5),
          plot.caption = element_text(size = 8,
                                      margin = margin(t = 10),
                                      color = "#3D4852"), 
          title = element_text (size = 15,margin = margin(b = 10)),
          legend.position="bottom") +
    expand_limits(x=0,y=0)
}
```


* Radar (or spider) graphs comparing the differences of scores between 2 groups

<to dos: generate graphics with dummy data to show examples of each>

### Creating Segmentats
* Creates segments with the optimal groups at x, y, and z number of segments
* Uses Latent Profile Analyses to explain which factors explain each segment and how much of an impact each factor has on the between group differences

Groups and condition on need




------------------------------------------------------------------------

## Using the JTBD Package

```{r}
library(quantjtbd)
```

```{r }

```

## Sample Workflow

### Import your SPSS data into R

```{r eval=FALSE}

 df_spss  <-  haven::read_sav("YOUR_FILE.sav")
# Check out the data and their labels via the Labeled package's Dictionary functionality
 dictionary <- labelled::generate_dictionary(df_spss)
```

## Reanme Your Columns In This Format

To be honest, the hardest part of this package is getting the data in a format that the package can accept. 

Each column needs to be labelled in the following format:

* "imp__"/"sat__" + "your_job_step_name" + ".name_of_job"
* No spaces anywhere
* Job Step and Name of Jobs must literally __exactly__ match^[I have a MAJOR trauma because somehow a "no break space" character (unicode U+00A0, "space" + "option" key on mac) got inserted instead of spaces for the satisfaction section when exporting data from SurveyMonkey. It took me hours (days?) of debugging to find out why they weren't matching as these are invisible in excel format.] between the importance & satisfaction columns--the only thing that should be different is the "imp" or "sat" prefix.

Here are a few sample column names:

* imp__researching.minimize_time_to_evaluate_options
* sat__researching.minimize_time_to_evaluate_options
* imp__purchasing.minimize_time_to_receive_payment_confirmation
* sat__purchasing.minimize_time_to_receive_payment_confirmation

#### Labeling SPSS (.sav) Data Using QuantJTBD

Load the data (ideally via SPSS) because we want to use the column labels in the graphics so you know which scores correspond to which objectives.
The `build_imp_column_names` and `build_sat_column_names` functions primarily renames the column names (it also change it to factor).

Currently it accepts a standard format given from survey instruments which is:
`DistinctQuestionId_Question_Text - How Important...` for importance columns and `DistinctQuestionId_Question_Text - How Satisfied...` for satisfaction.

If your data isn't in this format, you'll have to rename them manually (which isn't so bad likely using `mutate`)

Here is specifically what `build_imp_column_names` and `build_sat_column_names` do:

+ Swap the labels and the column names
+ Remove the prefix by splitting on space
+ Remove the suffix by splitting on "-"
+ Change any spaces in the names to underscores
+ Prefix the updated columns with the needed `imp__`, `sat__`, and `.job_ _section` portions of the column name
+ Change all `haven` data labels to factors (not a renaming task, but it's part of this function for now)

```{r eval=FALSE}
# Example
df_renamed_imp_cols <- build_sat_column_names(df_imp_only_cols,"Job_Step_Name")
df_renamed_sat_cols <- build_imp_column_names(df_sat_only_cols,"Job_Step_Name")
df_merged_imp_sat_cols <- cbind(df_renamed_imp_cols,df_renamed_sat_cols) 
```

### Renaming the columns some other way

Column naming __RULES__ in order to be able to use the package:

* Each job step (`imp__JOB_STEP.job_name`) must be DISTINCT from other job steps
* Each job name (`imp__job_step.JOB_NAME`) must be DISTINCT from other job names
* Each job step and job name (`imp__JOB_STEP.JOB_NAME`) must be IDENTICAL between the importance and satisfaction columns--the only thing that changes is the prefix: `imp__researching.minimize_time_to_evaluate_options`  `sat__researching.minimize_time_to_evaluate_options`
* You must have an importance and satisfaction column for every job you want to calculate  
* No spaces in the column name
* __Data must be in factor format__ 

## Package Todo List

Build it for this survey THEN make it extensible

* Add Stat sig calculations for the pairwise comparisons
* Get the code working on this new survey
* Split each function into sub functions
* Create visualizations
* Improve the recode functions for SPSS
  * Allow the user to specify the delimiters
  * We shouldn't need to make either delimiter optional
* Vignette
  * Add in more sample graphics
  * Split everything into pages
  * Figure out how to split functions into specific functions and global functions
* Figure out compare 2 code
* Improve visual output of 
  * Tables (watermark? colors?)
  * Graph the high-value opporunities
  


### Do Not Do List
* Avoid building functions for descritive statistics


## Random Musings About JTBD
From my experience doing JTBD projects in multiple industries, the jobs are largely the same at [higher levels](#), but get more distinct (and also [more useful for product decisions](#)) at lower levels.
